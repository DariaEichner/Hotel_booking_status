---
title: "Report on Hotel Booking Status Prediction"
author: "Daria Eichner"
date: "5/29/2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
  github_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
################################
# Load Data
################################
# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(ggridges)) install.packages("ggridges", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(CatEncoders)) install.packages("CatEncoders", repos = "http://cran.us.r-project.org")
if(!require(xgboost)) install.packages("xgboost", repos = "http://cran.us.r-project.org")


# Hotel booking demand datasets:
# https://www.sciencedirect.com/science/article/pii/S2352340918315191
# https://www.kaggle.com/jessemostipak/hotel-booking-demand?select=hotel_bookings.csv

#Load CSV file 
#Load CSV file 
file_name <- "hotel_bookings.csv" 
csv_file <-  read.csv(file_name, na.strings=c("NA","<NA>",""," ",".","?","NULL"))

# setting order of arrival_date_month -> Jan,Feb...Dec
csv_file$arrival_date_month<-factor(csv_file$arrival_date_month,levels = c("January","February","March","April","May","June","July","August","September","October","November","December"))

```
## Introduction
This report will guide you through building a predictive machine learing model based on a hotel booking demand dataset, provided by Kaggle.The data was obtained from this URL (https://www.kaggle.com/jessemostipak/hotel-booking-demand?select=hotel_bookings.csv)
as well as an article written by Nuno Antonio, Ana Almeida, and Luis Nunes for Data in Brief, Volume 22, February 2019 URL(https://www.sciencedirect.com/science/article/pii/S2352340918315191).

In the hotel booking dataset each row represens various information on a hotel booking by one customer. One categorical column "is_canceled" contains the booking status, whether the booking was canceled (1) or not (0). We will build a model to predict this booking status.

## Methods/Analysis
In this section, I will describe the different methods I used, such as feature selection, PCA and model Stacking to predict the outcome of a booking.

First lets explore the dataset to get insights and make informed decision about feature selection.

```{r eda step1 function in R}

# What is the size of the dataset
csv_file%>% dim()

#what is the data type of each column  and the frist 3 values in the data frame
col_type <-sapply(csv_file, class)
#frist 3 values of each column
tab<-csv_file %>% head(3) %>% t()
#display data
knitr::kable(cbind(col_type,tab))

```

There are 32 columns in the dataset, describing hotel bookings for one resort hotel and the other is a city hotel. The bookings contain a vararity of information like average daily rate (ADR), number of guest (adults, children and babies), room type, meal or date of arrival.   

The name of the binary outcome column is "is_canceld", lets see if there is an imbalance in distribution of the classes. An even distribution of the outcome class would be 0.5 each. Knowing that the distribution of the outcome class has a bias towards "not canceled" will be helpfull in a later step, when the metrics to evaluate the performance of a machine learning algorithm will be define.

```{r eda step2 function in R,echo = FALSE, out.width = "50%"}
# check the distribution of the booking status 
# how high is the cancellation rate
csv_file %>% 
  select(is_canceled) %>%  
  group_by(is_canceled) %>%
  summarise(count_n=n()) %>%
  mutate(percent=count_n/sum(count_n))%>%
  ggplot(aes(is_canceled,percent,fill =factor(is_canceled))) +
  geom_bar(stat="identity",width = 0.6)+
  geom_text(aes(label=round(percent,digits = 2)), vjust=1.6, color="black", size=3.5)+
  scale_fill_discrete(
    name = "Booking Status",
    breaks = c("0", "1"),
    label = c("Not Canceled", "Canceled")
  )
```

Let futher investigate, if the distribution of the outcome changes for each hotel. The city hotel has a higher cancellation rate of 42% compared to 28% at the resort hotel. There seems to be a behavioral pattern. 

```{r eda step3 function in R,warning=FALSE,echo = FALSE,out.width = "50%"}
# how high is the cancellation rate
csv_file %>% 
  select( hotel,is_canceled) %>%  
  group_by(hotel,is_canceled) %>%
  summarise(count_n=n()) %>%
  mutate(percent=count_n/sum(count_n))%>%
  ggplot(aes(is_canceled,percent,fill =factor(is_canceled))) +
  geom_bar(stat="identity",width = 0.6)+
  geom_text(aes(label=round(percent,digits = 2)), vjust=1.6, color="black", size=3.5)+
  scale_fill_discrete(
    name = "Booking Status",
    breaks = c("0", "1"),
    label = c("Not Canceled", "Canceled")
  )+
  facet_grid(.~hotel)
```

What is the distribution of Average Daily Rate (ADR) by hotel? The city hotel has a higher avg rate compared to the resort hotel. 

```{r eda step4 function in R,warning=FALSE,echo = FALSE,out.width = "50%"}

#how does the booking status  change across month by hotel
# how does the Average Daily Rate change across Hotels
csv_file %>% 
  select( hotel,adr, is_canceled,arrival_date_month) %>% 
  filter(is_canceled==0) %>% 
  ggplot(aes(adr,fill=hotel)) +
  geom_density(alpha = 0.5)+
  scale_fill_manual(values=c("#999999", "#56B4E9"))+
  labs(title = "",x = "ADR")

```

How does the Average Daily Rate change across month and hotel? While the city hotel has higher daily rates on average, the resort hotel has the hightes rates in the summer month overall with a strong winter/summer seasonality.        

```{r eda step5 function in R,warning=FALSE,echo = FALSE,out.width = "70%"}
#how does the the Average Daily Rate change across different months
csv_file %>% filter(adr<5000)%>%
  ggplot(aes(arrival_date_month,adr, fill = hotel)) +
  geom_boxplot() +
  scale_fill_manual(values=c("#999999", "#56B4E9"))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "",x = "ADR")
```

Lets have a look on a categorical feature named customer type and the hotel preference. 50% of all bookings are generated by the customer type "Transient" at the city hotel.

```{r eda step6 function in R,warning=FALSE,echo = FALSE,out.width = "50%"}
# what is the most used customer type  by hotel
table(csv_file$customer_type,csv_file$hotel)

# what is the prefered  customer type  by hotel
csv_file%>%ggplot(aes(y = (..count..)/sum(..count..),x=customer_type, fill = hotel)) + 
  geom_bar(stat = "count", position = position_dodge()) + 
   scale_y_continuous(labels=scales::percent) +
          ylab("relative frequencies") +
  scale_fill_manual(values=c("#999999", "#56B4E9"))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        panel.background = element_blank())
```


How many nights do the guests stay at the hotel? By combining the data from  two columns stays_in_weekend_nights and stays_in_week_nights one get the average number of nights guests stay at each hotel and month. While guest stay around 3 nigths at the city hotel, the guests of the resort hotel stay longer up to 7 nights in the summer.  

```{r eda step7 function in R,warning=FALSE,echo = FALSE,out.width = "50%"}
# how long do people stay at the hotel by month and hotel
csv_file %>%
  group_by(arrival_date_month,hotel) %>%
  mutate(nights = mean(stays_in_weekend_nights + stays_in_week_nights)) %>%
  arrange(arrival_date_month,nights)%>%
  ggplot(aes(arrival_date_month,nights,fill=hotel))+
  geom_bar(stat = "identity",position = 'dodge')+
  scale_fill_manual(values=c("#999999", "#56B4E9"))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        panel.background = element_blank())+
  labs(title = " Avg # of stays by Month and Hotel",x = "")
```

How does the reservation status relate to the booking status? While the booking status "is_canceled" indicates if the booking was canceled (1) or not (0), the reservation status is a bookings last status (canceled; Check-Out; No-Show). Because the reservation status is almost idenical with the booking status, it will be removed from the dataset together with Reservation_Status_Date.

```{r eda step8 function in R,warning=FALSE,echo = FALSE,out.width = "50%"}
# how does the reservation_status change by booking status
table(ifelse(csv_file$is_canceled==1,"Canceled ","Not Canceled"),csv_file$reservation_status)
```


### Preprocessing and Transformation

An important part of the data preprocessing is the identification of missing values in the dataset.  
```{r prepro1  function in R,warning=FALSE,out.width = "50%"}
apply(is.na(csv_file), 2, sum) %>%  knitr::kable()
```

There are 4 columns children, country, agent and company with null vaules that need to be replaced with meaningful values that can be handeled by an algorithm

```{r prepro2  function in R,warning=FALSE,out.width = "50%"}
# replacing missing values
hotel_booking <-csv_file %>% 
  mutate(children = ifelse(is.na(children), 0,children),
         country= factor(ifelse(is.na(country), 'Unknown',levels(country))),
         agent= ifelse(is.na(agent), 0,agent),
         company= ifelse(is.na(company), 0,company))
```


Another important step of data preprocessing is the transformation of existing data into new information.
The arrival_date_month contains the name of the month of arrival: “January” to “December”. This column will be transformed into a number 1 to 12. Further we add two columns stays_in_weekend_nights and stays_in_week_nights to get the total nights a guest stays at a hotel. The total number of guests is obtained by adding  adults, children and babies into one column names guests. Because there are only few data points `r mean(ifelse(hotel_booking$children+ hotel_booking$babies>0,1,0))*100`% of bookings that have data on children or babies, the information will be transformed into a new column is_family.  


```{r prepro3  function in R,warning=FALSE}

# Transforming and adding new features 
hotel_booking <-hotel_booking%>%
  mutate(
    arrival_month =as.numeric(arrival_date_month), 
    total_nights=stays_in_weekend_nights + stays_in_week_nights,
    guests=as.integer(adults + children+ babies),
    is_family= ifelse(children+ babies>0,1,0)
    )
```


All columns that have been used in the transformation will be removed from the dataset to aviod redundacy.
Also the reservation_status_date and reservation_status will be removed the information is almost identical to the outcome variable we want to predict.

```{r prepro4  function in R,warning=FALSE}

#Drop reservation status and date as well as features that have been transformed into new columns
hotel_booking <-select(hotel_booking, -c(reservation_status,
                                         reservation_status_date,
                                         stays_in_weekend_nights,
                                         stays_in_week_nights,
                                         children, 
                                         babies,
                                         adults,
                                         arrival_date_month
                                         ))
```

### Feature selection for categorical variables:
The booking data contains numerical and categorical data. We will identify the categorical data first and save the names of the columns for further use.   
```{r feat1  function in R,warning=FALSE}
# Saving names of categorical variables
categorical_name <- names(which(sapply(hotel_booking, is.factor)))
hotel_booking[,c(categorical_name)] %>% str() 

```

There are 9 categorical columns in total. The package caret has a model called rpart. Rpart will run a tree-based classification model, if the variables are factors, which is true in our case. We will use this model to predict the outcome is_canceled based on the categrical variables only. 

```{r feat2  function in R,warning=FALSE,out.width = "50%"}
# Feature importance of categorical variables with rpart model
set.seed(1, sample.kind="Rounding")
# use of cross-validation 
fitControl <- trainControl(## 3-fold CV
  method = "cv",
  number = 3
  )
#training the mode rpart on the categorical columns in Hotel booking dataset
train_cat_var <- train(as.factor(is_canceled)~.,
                       hotel_booking[,c(categorical_name,"is_canceled")],
                       method = "rpart",
                       metric = "Accuracy",
                       trControl = fitControl)
#Variable Importance of catecorical columns
imp_cat <-varImp(train_cat_var)
#plot the 10 most important variables
plot(imp_cat, top = 10)
```

We use the tree model as an approach to identify the importance of categorical variable in the hotel dataset. To define variable importance we count how often a predictor is used in the individual trees. Based on the output of the variable importance plot, only 6 out of 9 variable will be used in the predictive model.

```{r feat3  function in R,warning=FALSE}
#only the 6 variabels with a ranking >0 will remain
remain_cat_name <- c("deposit_type","distribution_channel","market_segment","assigned_room_type",
                     "customer_type","hotel")
```

### PCA for numerical variables:
This section will explain how Principal component analysis (PCA) is applied as a mean to achieve a efficient summary of our numerical variables in the hotel booking dataset.    

PCA is defined as an orthogonal linear transformation that transforms the data to a new coordinate system.
The function prcomp() returns both the rotation needed to transform the columns so that the variability of the columns is decreasing from most variable to least as well as the resulting new matrix (accessed with x). To normalize the data we can use the paramater "scale = TRUE".

```{r feat4  function in R,warning=FALSE}
# Saving names of numerical variables
numeric_name <- names(which(sapply(hotel_booking, is.numeric)))

#use PCA to reduce the number of features in the model
pca_numerical<-hotel_booking[,c(numeric_name)]%>% select(-is_canceled)%>%prcomp(scale = TRUE)

#Find the the number of Components covering 95% of variance 
summary(pca_numerical)
```

The PCA summary shows in the row "Cumulative Proportion" that it takes 15 out of 18 components to get at least 95% of the variability in the data. We will use this 15 PCA stored in pca_numerical$x as an intput into our model.

#### Creating a train and test set
In the next step the training and test dataset will be created. I will pick a 80% - 20% ratio for train and test dataset size.   
 
```{r train  function in R,warning=FALSE}
#create dataset using of the PCA and categorical variables
dataset <- as.data.frame(cbind(pca_numerical$x[,1:15],hotel_booking[,c(remain_cat_name,"is_canceled")]))

# Train/Test set will be 20%
set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y = dataset$is_canceled, times = 1, p = 0.2, list = FALSE)
train_data <- dataset[-test_index,]
test_data <- dataset[test_index,]

#house keeping
rm(hotel_booking, csv_file, pca_numerical, dataset,train_cat_var)
```

### Performance Evalation
There are several metrics that we can use to evaluate an algorithm in a way that prevalence does not cloud our assessment. As seen in the analyis of the distribution of the outcome variable in the hotel booking dataset, the booking status "not canceled" has a mean value of 0.63 compared to 0.37 "canceled". Because the data has a bias, our trained model will also  have a bias which needs to be addressed in the evaluation of the model. By studing sensitivity (Recall) and specificity (Precision) separately we can overcome this bias, by defining sensitivity as the ability of an algorithm to predict a positive outcome when the actual
outcome is positive. Addinionaly we will use specificity, which is defined as the ability of an algorithm to not predict a positive outcome when the actual outcome is not a positive. 

In order to have one evaluation metrics the F1 score is used as a balanced accuracy taking both sensitivity (Recall) and specificity (Precision) into account.  

  $F_{1} =2*\frac{precision * recall}{precision + recall}$

The caret function F_meas() computes this metrics for us once we define what category “positive” is. The function expects factors as input, and the first level is considered the positive outcome. In our example, 0 "not canceled" is the first level because it comes before 1 "canceled".

### Model creation
This section will contain the training of 3 basic models GLM (Generalized Linear Models) as a logistic regression, Rpart (Recursive Partitioning And Regression Trees) and KNN (K-Nearest Neighbour Classification). This three models will be trained by using cross-valiation on the training dataset. The evaluation of the model will be performed on the test dataset using F1- Score as the performance metric.

#### Model Stacking
To improve the overall performance of the hotel booking status model the predictions of the class probabilities for each basic model will be saved and used as an input variable for a forth model GBM (Gradient Boosting Machine). This top layer model will be used to make the final outcome prediction.  

**GBM:**
  - GLM
  - Rpart
  - KNN

#### First model: GLM
```{r model1 function in R,warning=FALSE}
#Setting parameters for Cross Validation
fitControl <- trainControl(method = "cv", 
                           number = 10, 
                           p = .9,
                           savePredictions = 'final', # To save out of fold predictions for best parameter combinantions
                           classProbs = T # To save the class probabilities of the out of fold predictions
)
#Training the general logistic regression  model
train_glm <- train(is_canceled~.,
                   train_data,
                   method = "glm",
                   family = "binomial",
                   trControl = fitControl)

#predict y_hat_glm for test_data
p_hat_glm <- predict(train_glm, newdata = test_data)
y_hat_glm <- ifelse(p_hat_glm >= 0.5, 1, 0) %>% factor()
# saving F1 Score for Logistic Regression Model
result_1 <- F_meas(data = y_hat_glm, reference = factor(test_data$is_canceled))
f1_results <- data_frame(method = "glm", 
                         f1_score =result_1,
                         Recall=sensitivity(data = y_hat_glm, reference =factor(test_data$is_canceled)),
                         Precision=specificity(data = y_hat_glm, reference =factor(test_data$is_canceled)))

f1_results%>%  knitr::kable()

```

#### Second model: Rpart

```{r model2 ,warning=FALSE}
# 2 Model RPart
set.seed(1, sample.kind="Rounding")
train_rp <- train(is_canceled~.,
                  train_data,
                  method = "rpart",
                  tuneGrid = data.frame(cp = 0),
                  trControl = fitControl)

# Predict y_hat_rp
p_hat_rp <- predict(train_rp, newdata = test_data)
y_hat_rp <- ifelse(p_hat_rp >= 0.5, 1, 0) %>% factor()
# saving F1 Score for Rpart Model
result_2 <-F_meas(data = y_hat_rp, reference = factor(test_data$is_canceled))
f1_results <- bind_rows(f1_results,
                        data_frame(
                          method = "rpart", 
                          f1_score =result_2,
                          Recall=sensitivity(data = y_hat_rp, reference = factor(test_data$is_canceled)), 
                          Precision=specificity(data = y_hat_rp, reference = factor(test_data$is_canceled))))
f1_results%>% filter(method == "rpart")%>%  knitr::kable()
```

#### Third model: KNN

```{r model3 ,warning=FALSE}
# 3 Model KNN
train_knn <- train(is_canceled~.,
                   data=train_data,
                   method = "knn",
                   tuneGrid = data.frame(k = 7),
                   trControl = fitControl)

#predict  y_hat_knn
p_hat_knn <- predict(train_knn, newdata = test_data)
y_hat_knn <- ifelse(p_hat_knn >= 0.5, 1, 0) %>% factor()
#The F1-score can be adapted to weigh specificity and sensitivity differently.
result_3 <-F_meas(data = y_hat_knn, reference = factor(test_data$is_canceled))
f1_results <- bind_rows(f1_results,
                        data_frame(method = "knn", 
                                   f1_score =result_3,
                                   Recall=sensitivity(data = y_hat_knn, reference = factor(test_data$is_canceled)), 
                                   Precision=specificity(data = y_hat_knn, reference = factor(test_data$is_canceled))))
f1_results%>% filter(method == "knn")%>%  knitr::kable()
```

We know have trained three basic machine learning models and will use the class probabilities of the outcome form each model and save it in a new dataset __train_pred_oof__ with three new variables as input for the last model GBM.

```{r oof ,warning=FALSE}

#Predicting the out of fold prediction probabilities for training data
train_pred_oof <- data.frame(glm  = train_glm$pred$pred[order(train_glm$pred$rowIndex)],
                             rpart= train_rp$pred$pred[order(train_rp$pred$rowIndex)],
                             knn  = train_knn$pred$pred[order(train_knn$pred$rowIndex)]
)

#Predicting probabilities for the test data
test_pred <- data.frame(glm  = predict(train_glm,newdata = test_data),
                        rpart= predict(train_rp,newdata = test_data),
                        knn  = predict(train_knn,newdata = test_data)
)
```

#### Stacking: GBM
The new training dataset is called train_pred_oof and the new testing dataset is called test_pred.
Both contain three variable with probabilities for the outcome of the booking status. The top layer model GBM will be used to predict the final prediction. 
```{r stacking ,warning=FALSE}
#Using GBM as top layer model and OOF as features
top_layer_gbm<- train(x=train_pred_oof,y=train_data$is_canceled,
                      method='gbm',
                      trControl = fitControl,
                      verbose = FALSE)

#predict test data using GBM as final layer model
p_hat_stacked <- predict(top_layer_gbm,newdata=test_pred)
y_hat_stacked <- ifelse(p_hat_stacked >= 0.5, 1, 0) %>% factor()
#The F1-score can be adapted to weigh specificity and sensitivity differently.
result_4 <-F_meas(data = y_hat_stacked, reference = factor(test_data$is_canceled))
#Saving results to Acc_results
f1_results <- bind_rows(f1_results,
                        data_frame(method = "GBM", 
                                   f1_score =result_4,
                                   Recall=sensitivity(data = y_hat_stacked, reference = factor(test_data$is_canceled)), 
                                   Precision=specificity(data = y_hat_stacked, reference = factor(test_data$is_canceled))))

f1_results%>% filter(method == "GBM")%>%  knitr::kable()
```

## Results 
We will use the findings from the analysis and the trainig of three basic models on the train dataset to build a predictive model for our test dataset.

```{r results_model, warning=FALSE}
#Using GBM as top layer model and OOF as features
top_layer_gbm<- train(x=train_pred_oof,y=train_data$is_canceled,
                      method='gbm',
                      trControl = fitControl,
                      verbose = FALSE)

#predict test data using GBM as final layer model
p_hat_stacked <- predict(top_layer_gbm,newdata=test_pred)
y_hat_stacked <- ifelse(p_hat_stacked >= 0.5, 1, 0) %>% factor()
#The F1-score can be adapted to weigh specificity and sensitivity differently.
result_4 <-F_meas(data = y_hat_stacked, reference = factor(test_data$is_canceled))
#Saving results to Acc_results
f1_results <- bind_rows(f1_results,
                        data_frame(method = "GBM", 
                                   f1_score =result_4,
                                   Recall=sensitivity(data = y_hat_stacked, reference = factor(test_data$is_canceled)), 
                                   Precision=specificity(data = y_hat_stacked, reference = factor(test_data$is_canceled))))

f1_results%>%knitr::kable()
```

## Conclusion  
There is great value in using machine learning models to predice the outcome of a hotel booking. It can help to improve revenues from a hotel operation, if the prediction can be used to improve capacity planning.  

The effectiveness of the predictive model depends on the method and algorithems it uses to generate information. This projects presents a method called "stacking" that uses basic fast running algorithems to be used as an input for a top layer algorithem that makes predictions of a hotel booking status. By combining the prediction of probabilities of three model into one top layer model, the accuracy of the model improved.

### Futur Work

To further impove the prediction, I will use an argument in the train() function called tuneGrid that is available through the caret package. The argument tuneGrid can take a data frame with columns for each tuning parameter. Each  method used in this report (glm, rpart, knn, gbm) has its own set of tunig parameters. Because it requries alot of computing power to train models and fine tune each parameter, this step was left out.












